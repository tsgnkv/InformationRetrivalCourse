{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/a.tsigankov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/a.tsigankov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "mystem = Mystem()\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(filename):\n",
    "    \"\"\"Чтение XML-файла и получение pandas.DataFrame\"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    temp = []\n",
    "    for child in root:\n",
    "        # child[0] - speech; child[1] - evaluation; child[2] - url\n",
    "        temp.append([child[0].text.strip(), child[1].text.strip(), child[2].text.strip()])\n",
    "    df = pd.DataFrame(temp)\n",
    "    df.columns = ['speech', 'evaluation', 'url']\n",
    "    df = df[df.evaluation.isin(['0', '+', '-'])]\n",
    "    df = df.reset_index().drop('index', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(value):\n",
    "    \"\"\"Переимненование колонки с оценками в читаемый формат\"\"\"\n",
    "    if value == '0':\n",
    "        return 0\n",
    "    if value == '+':\n",
    "        return 1\n",
    "    if value == '-':\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(sentence):\n",
    "    \"\"\"Лемматизирует предложение\"\"\"\n",
    "    return ''.join((mystem.lemmatize(' '.join(tokenizer.tokenize(sentence))))).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    \"\"\"Удаляет стоп-слова\"\"\"\n",
    "    return ' '.join([word for word in sentence.split(' ') if word not in russian_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_xml('data/train/news_eval_train.xml')\n",
    "test = read_xml('data/test/news_eval_test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['part'] = 'train'\n",
    "test['part'] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train, test]).reset_index().drop('index', axis=1)\n",
    "combined = pd.concat([combined, pd.get_dummies(combined.evaluation)], axis=1)\n",
    "\n",
    "combined.columns = ['speech', 'evaluation', 'url', 'part', 'positive', 'negative', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['evaluation'] = combined.evaluation.apply(rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['lemmatized_speech'] = combined.speech.apply(lemmatize)\n",
    "combined['lemmatized_speech'] = combined.lemmatized_speech.apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(combined['evatuation_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>url</th>\n",
       "      <th>part</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>evatuation_new</th>\n",
       "      <th>lemmatized_speech</th>\n",
       "      <th>evatuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Далее в своей проповеди он напомнил, что по би...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.blagovest-info.ru/index.php?ss=2&amp;am...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>далее свой проповедь напоминать библейский рас...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Меня отпустили. У Коли @nlyaskin забирают вещ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://asiareport.ru/index.php/news/14440-chir...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>отпускать коля nlyaskin забирать вещь сажать х...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В интервью РИА \"Новости\" уполномоченный по пра...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.rosbalt.ru/federal/2012/04/08/96718...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>интервью риа новость уполномоченный право ребе...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Бывший главный тренер сборной Англии Грэм Тэйл...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.sports.ru/football/139754406.html</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>бывший главный тренер сборная англия грэм тэйл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"На телах жертв были обнаружены многочисленные...</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://moldinfo.ru/narod/2939-jitel-vengerskoy...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>тело жертва обнаруживать многочисленный колоть...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech  evaluation  \\\n",
       "0  Далее в своей проповеди он напомнил, что по би...           0   \n",
       "1  \"Меня отпустили. У Коли @nlyaskin забирают вещ...          -1   \n",
       "2  В интервью РИА \"Новости\" уполномоченный по пра...           0   \n",
       "3  Бывший главный тренер сборной Англии Грэм Тэйл...           0   \n",
       "4  \"На телах жертв были обнаружены многочисленные...          -1   \n",
       "\n",
       "                                                 url   part  positive  \\\n",
       "0  http://www.blagovest-info.ru/index.php?ss=2&am...  train         0   \n",
       "1  http://asiareport.ru/index.php/news/14440-chir...  train         0   \n",
       "2  http://www.rosbalt.ru/federal/2012/04/08/96718...  train         0   \n",
       "3       http://www.sports.ru/football/139754406.html  train         0   \n",
       "4  http://moldinfo.ru/narod/2939-jitel-vengerskoy...  train         0   \n",
       "\n",
       "   negative  neutral evatuation_new  \\\n",
       "0         0        1      [neutral]   \n",
       "1         1        0     [negative]   \n",
       "2         0        1      [neutral]   \n",
       "3         0        1      [neutral]   \n",
       "4         1        0     [negative]   \n",
       "\n",
       "                                   lemmatized_speech  evatuation  \n",
       "0  далее свой проповедь напоминать библейский рас...           0  \n",
       "1  отпускать коля nlyaskin забирать вещь сажать х...          -1  \n",
       "2  интервью риа новость уполномоченный право ребе...           0  \n",
       "3  бывший главный тренер сборная англия грэм тэйл...           0  \n",
       "4  тело жертва обнаруживать многочисленный колоть...          -1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = combined[combined.part == 'train']\n",
    "train_y = combined['evaluation'][train_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = combined[combined.part == 'test']['lemmatized_speech']\n",
    "test_y = combined['evaluation'][test_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# деление обучающей выборки на тренировочную и валидационную\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data['lemmatized_speech'], \n",
    "                                              train_y, \n",
    "                                              test_size=0.25, \n",
    "                                              random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "freq_vectorizer = CountVectorizer(binary=False)\n",
    "binary_vectorizer = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [tfidf_vectorizer, freq_vectorizer, binary_vectorizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vectorizer in vectorizers:\n",
    "    vectorizer.fit(combined['lemmatized_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    GaussianNB(),\n",
    "    SVC(),\n",
    "    LogisticRegression()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vectorizer in vectorizers:\n",
    "    \n",
    "    transformed_train = vectorizer.transform(x_train).toarray()\n",
    "    transformed_val = vectorizer.transform(x_val).toarray()\n",
    "    transformed_test = vectorizer.transform(test_data).toarray()\n",
    "    \n",
    "    \n",
    "    for model in models:\n",
    "        print(vectorizer, model)\n",
    "        model.fit(transformed_train, y_train)\n",
    "    \n",
    "        print(model.score(transformed_train, y_train), \n",
    "              model.score(transformed_val, y_val),\n",
    "              model.score(transformed_test, test_y))\n",
    "        print('========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итоговая таблица\n",
    "\n",
    "|               | TfIdfVectorizer                                                                      | CountVectorizer                                                                      | CountVectorizer(Binary)                                                              |\n",
    "|---------------|--------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| Naive Bayes   | train 0.9739636861939021<br>validation 0.5995893223819302<br>test 0.5134485020774109 | train 0.9739636861939021<br>validation 0.5954825462012321<br>test 0.5217581456374372 | train 0.9739636861939021<br>validation 0.6026694045174538<br>test 0.5311611633500984 |\n",
    "| SVM           | train 0.9952038369304557<br>validation 0.6273100616016427<br>test 0.549092499453313  | train 0.9290853031860226<br>validation 0.6098562628336756<br>test 0.549529849114367  | train 0.9510106200753683<br>validation 0.6180698151950719<br>test 0.5578394926743931 |\n",
    "| LogRegression | train 0.9277149708804385<br>validation 0.6344969199178645<br>test 0.5877979444565931 | train 0.9982870846180198<br>validation 0.6303901437371663<br>test 0.584517821998688  | train 0.9982870846180198<br>validation 0.6201232032854209<br>test 0.5877979444565931 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что наивный байесовский классификатор показывает лучшую точность при использовании бинарных векторов. SVM тоже. Логистическая регрессия показала одинаковый лучший скор на tf-idf и бинарных векторах, на частотных получается точность меньше.\n",
    "\n",
    "Возьмем для дальнейшего повышения точности модель логистической регресии и попробуем подобрать гиперпараметры алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train = tfidf_vectorizer.transform(train_data['lemmatized_speech']).toarray()\n",
    "transformed_val = tfidf_vectorizer.transform(x_val).toarray()\n",
    "transformed_test = tfidf_vectorizer.transform(test_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l2'}\n",
      "accuracy : 0.6534651570301389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {\n",
    "    \"C\": np.logspace(-3, 3, 7), \n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "       }\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg_cv = GridSearchCV(logreg, grid, cv=5)\n",
    "logreg_cv.fit(transformed_train, train_y)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \", logreg_cv.best_params_)\n",
    "print(\"accuracy :\", logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = logreg_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = best_estimator.predict(transformed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro score на тесте: 0.5633681303779071\n",
      "Precision score на тесте: 0.6059479553903345\n"
     ]
    }
   ],
   "source": [
    "print(f'F1-macro score на тесте: {f1_score(test_y, predictions_test, average=\"macro\")}')\n",
    "print(f'Precision score на тесте: {accuracy_score(test_y, predictions_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТОП-10 слов, который имеют большой вес для определения негативной новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сожаление', 4.936326682259362),\n",
       " ('нарушение', 4.890987946812722),\n",
       " ('угроза', 4.580912586451019),\n",
       " ('преступление', 4.542984377309094),\n",
       " ('убийство', 4.181212655600939),\n",
       " ('собчак', 4.152501310704225),\n",
       " ('оказываться', 3.8783418935142313),\n",
       " ('либо', 3.8698927886648726),\n",
       " ('происходить', 3.863872399546387),\n",
       " ('слишком', 3.8004973995593345)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative\n",
    "sorted(list(zip(vocabulary, best_estimator.coef_[0])), key=lambda x: x[1])[::-1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТОП-10 слов, который имеют большой вес для определения нейтральной новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('определять', 4.69703481940328),\n",
       " ('кандидатура', 4.391496766714534),\n",
       " ('пока', 4.289327951457688),\n",
       " ('использование', 4.116453160770193),\n",
       " ('рассматривать', 4.0389977393768675),\n",
       " ('особенность', 3.769035522816867),\n",
       " ('эксперт', 3.655620586625588),\n",
       " ('аналитик', 3.5675683066037585),\n",
       " ('избирательный', 3.5198144964324634),\n",
       " ('валюта', 3.4750652052439177)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neutral\n",
    "sorted(list(zip(vocabulary, best_estimator.coef_[1])), key=lambda x: x[1])[::-1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТОП-10 слов, который имеют большой вес для определения позитивной новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хороший', 7.834050834491842),\n",
       " ('позволять', 5.846755152602537),\n",
       " ('помогать', 5.1105934272140106),\n",
       " ('награда', 4.9070940905423015),\n",
       " ('наш', 4.6922175936377295),\n",
       " ('важный', 4.620315495972576),\n",
       " ('интересный', 4.525986734544588),\n",
       " ('подчеркивать', 4.328234523106455),\n",
       " ('счастливый', 4.142579563022129),\n",
       " ('уровень', 3.96515242284804)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive\n",
    "sorted(list(zip(vocabulary, best_estimator.coef_[2])), key=lambda x: x[1])[::-1][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
